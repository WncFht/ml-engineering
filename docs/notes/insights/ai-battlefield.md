---
title: ai-battlefield
createTime: 2025/07/03 00:05:24
permalink: /notes/notes/xd7mkp42/
---
# AI战场工程 - 你需要知道什么

本章是一个人对 ML/AI 工程现实的固执己见的概述，这可能是也可能不是另一个人的现实。其目的是帮助您开始提出正确的问题，并满足您的 ML 工程需求。

## 基础知识

### 在人工智能竞赛中什么最重要？

训练：

1. 一个人能多快地训练出更好的模型（先发优势）
2. 花了多少钱（训练后我们还有钱给人才发工资吗？）

推理：

1. 快速延迟（用户习惯于毫秒级的响应时间，如果响应需要几秒钟，他们会离开）
2. 快速吞吐量（可以处理多少并发查询）
3. 每个用户花费多少 $$（我们能否租用更多 GPU 来获取更多用户和/或改进（1）和（2）？）

### LLM 训练的需求是什么？

1. 快速计算，绝大部分是矩阵乘法
2. 足够快的内存、IO、网络和 CPU 来为计算提供数据

推论：如果您购买或租用硬件时投资了最快的加速器，但在任何其他组件上吝啬，那么您就浪费了金钱，并且您可能无法赢得比赛，因为训练将需要更长的时间。

### 什么是机器学习的主力？

- 加速器或处理单元是完成大部分工作的设备。

- 由于 ML 进行了大量的并行处理（[SIMD](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data)），GPU 最初被使用，但现在你还有 TPU、IPU、FPGA、HPU、QPU、RDU 等。最近的 CPU 也开始被用作加速器，尤其是在推理方面。

[更多详情](../compute/accelerator)。

### 人工智能驱动实体

- AI 公司 - 训练模型/围绕自训练或他人训练的模型构建产品，进行内部研究。
- 学术界 - 进行大量研究并撰写论文。产生了许多新想法。
- AI 爱好者 - 有很多善意可用，一些人将资源/人才聚集在一起训练开放存取模型，由 HPC 和偶尔的云或大学集群捐赠计算资源。
- 企业家 - 有很多唾手可得的成果 - 创造性地转售服务，制作 ML 驱动的应用程序，并利用各种可用资源的巧妙组合创造出惊人的成果。

### 信息共享

- 令人非常惊讶的是，几乎所有参与 AI 领域的人都与社区分享了大量的发现。
- 当然，公司不会披露其所有的知识产权，但其中很多确实以知识或模型权重的形式共享出来
- 发表大量知识产权和模型的公司往往会吸引更高质量的人才。
- Twitter 似乎是关注正在发生的事情的中心平台

### AI 泡沫

- [互联网泡沫](https://en.wikipedia.org/wiki/Dot-com_bubble) 发生在 1995-2000 年。现在 AI 领域正在发生非常相似的情况。

- 有大量资金可用于创建新创公司或推动现有公司发展。筹集数百万美元相对容易。

- 由于我们正处于 AI 行业的"狂野西部"阶段，预测未来非常困难，因此只要听起来合理，几乎任何创业想法都可以。

- AI 泡沫与互联网泡沫的区别在于，运营一家互联网公司实际上并不需要太多资金 - 大部分筹集的资金都用于营销和一些员工，几乎没有用于计算。AI 公司需要数百万美元，因为训练 LLM 需要大量的计算资源，而这些计算资源非常昂贵。例如，1 个 NVIDIA H100 成本约为 3 万美元，一家公司可能需要 512 个，即 1500 万美元（不计算其他硬件组件和相关成本）！

## 机器学习工程师的天堂与地狱

这是我个人基于 LLM/VLM 训练的天堂与地狱。你的情况可能会有所不同。

### 机器学习工程师的天堂

1. 一个构建良好的 HPC，或一个全方位服务的基于云的集群，有人勤奋及时地照管硬件和系统。

   我只需要带上我的训练软件进行训练，这已经是一项需要特殊技能的极其复杂的工作。

2. 大量节点可供独家无限使用

3. 快速的节点间连接，不会成为加速器的瓶颈，并且不与其他用户共享

4. 巨大的本地超快速基于 NVME 的共享文件系统，可以容纳数据集和检查点

5. 带有 SLURM 和最少软件的裸机 Linux，能够启动训练作业

6. `sudoer` 权限，方便与团队合作

### 机器学习工程师的地狱

1. 一个云或内部集群，你必须做所有的事情 - 系统管理、更换硬件、处理停机等。然后还要在此之上进行训练。

2. 一个小而慢的共享文件系统（NFS？），从云端获取数据并保存检查点到云端

3. 缓慢的节点间连接导致加速器利用率低

4. 与其他用户共享节点间网络，这使得网络不稳定且不可预测

5. 超级复杂的云控制台，有无数的屏幕和步骤来设置即使是简单的事情

6. 无法快速更换出故障的硬件

7. 需要分时使用节点 - 训练作业之间有等待时间

8. 有其他并发用户可能会用光整个磁盘，导致训练崩溃

9. 无法杀死团队中其他人启动然后去睡觉的作业

## 获取计算资源

获取计算资源主要有 3 种选择：

- 在云上租用
- 在 HPC 上获得分时使用权
- 购买

### 在云上租用

这是目前获取计算资源的主要方式。

优点：

- 易于扩展或缩减集群规模
- 几年后易于从旧硬件升级到新一代硬件
- 集群管理可以轻松外包

缺点：

- 昂贵，除非你为数百个加速器谈判长期（1-3年）合同
- 你会被诱惑购买许多你可能需要或不需要的工具和服务
- 无论你是否充分使用集群，你总是会被收费

### 使用 HPC

HPC 并不多，因此可用资源有限。

优点：
- 为你管理 - 你所需要的只是你的训练软件和一些 [SLURM](../orchestration/slurm) 知识来启动作业
- 通常由当地政府/大学赞助 - 可能会以更少的钱甚至免费完成工作（例如，我们在 [JeanZay HPC](http://www.idris.fr/eng/jean-zay/) 上免费训练了 [BLOOM-176B](https://huggingface.co/bigscience/bloom)！）

缺点：
- 需要与其他团队分时共享计算资源 == 作业时间短，中间可能有很长的等待时间 - 可能难以快速完成训练
- 节点间网络可能不稳定，因为它将被其他团队使用
- 必须遵守 HPC 的规则（例如，没有 `sudo` 访问权限和各种其他规则）
- 在某种程度上，HPC 集群就是它本来的样子 - 你无法让网络更快，甚至安装某些软件也可能很棘手。

### 购买硬件

主要是大学购买和建立自己的集群，一些大公司也这样做。

优点：

- 如果你可以 24/7 部署硬件超过几年，总成本将比租用便宜
- 易于提供快速的本地存储 - 一个好的 NVME raid 会比在线存储便宜得多也快得多

缺点：

- 购买后仅几年，你就会被过时的硬件所困扰 - 也许可以转售
- 必须购买超出需要的数量 - 硬件容易损坏，尤其是在 24/7 使用时，RMA 可能需要数周时间
- 必须聘请人才来管理内部解决方案
- 必须解决冷却、电费、保险等问题

### 管理计算资源

- 除非你使用完全管理的 HPC 计算资源，否则你绝对需要聘请一名系统管理员。你可能会觉得你的 ML 工程师可以在他们的训练任务之间处理这些工作，但他们会浪费大量时间来管理磁盘空间、处理有问题的节点、要求用户遵守规则等。

## 技术需求

### 你能足够快地为熔炉送料吗？

想象一下蒸汽机车 - 引擎很棒，但如果[司炉](https://en.wikipedia.org/wiki/Fireman_(steam_engine))铲煤的速度不够快，火车就跑不快。

![](images/640px-Baureihe52Heizer.jpg)

[来源](https://commons.wikimedia.org/wiki/File:Baureihe52Heizer.jpg)

这就是当前 ML 硬件的现状：瓶颈在于移动数据位而不是计算。

- 加速器每 2 年速度提高约 2 倍（[摩尔定律](https://en.wikipedia.org/wiki/Moore%27s_law)）
- 网络和内存并非如此！现在两者都已成为计算瓶颈
- 如果你的 DataLoader 必须从云端拉取数据，IO 可能是另一个瓶颈
- 只要有足够的 cpu 核心用于 DataLoader 工作进程和主进程，CPU 就没问题

推论：研究整台机器，而不仅仅是它的引擎。

一个疯狂的想法：如果你能以它们计算的速度为它们提供数据，旧的 GPU 可能会做得很好。如果你能以与下一代 GPU 相同的成本获得 3 个旧 GPU，你可能会更早以更低的成本完成训练。

### TFLOPS

- 一旦你选择了模型的架构和大小，以及你想要为模型训练多少个 token，你就能立即知道完成这个目标需要多少计算量。具体来说，你现在可以计算出[需要多少次浮点运算](../training/performance/README.md#tflops-as-a-performance-metric)。

- 所缺的只是比较不同计算提供商的硬件每秒可以计算多少浮点运算（TFLOPS）以及它们的单位成本，现在你就可以计算出训练的总近似成本。

  1. 根据所考虑解决方案的 TFLOPS 计算训练所需的时间：
     `所需总 tflops / 该计算单元的 tflops = 以秒为单位的时间`
     假设结果是 604800 秒或 7 天。

  2. 查看使用此计算解决方案 7 天的成本，现在你就知道了训练此模型的总 $$。

  3. 查看其他提议并进行相同的计算 - 选择最佳选项。

- 如前所述，时间非常重要，因此如果更早完成训练很重要，因为你想成为第一个进入市场的，你可能仍会选择更昂贵的解决方案。

不幸的是，这种计算只是部分正确，因为宣传的峰值 TFLOPS 通常是无法实现的。MFU 部分将对此进行深入探讨。

### 模型 FLOPS 利用率 (MFU)

如上一节所述，一些（大多数？）供应商发布的峰值性能 TFLOPS 是不切实际的 - 它们无法实现。

模型 FLOPS 利用率（MFU）是告诉我们加速器利用率有多好的指标。其计算方法如下：

1. 通过计算单个训练迭代需要多少次浮点运算并将其除以该迭代所花费的秒数来测量实际 TFLOPS。
2. 将实际 TFLOPS 除以宣传的 TFLOPS 以获得 MFU

示例：假设您正在以 BFLOAT16 精度进行训练：

- 如果单次迭代需要 624 Tera 浮点运算，并且运行时间为 4 秒，那么我们知道我们得到：`624/4=156` 实际 TFLOPS
- 现在 BF16@A100 的[广告速度为 312TFLOPS](https://www.nvidia.com/en-us/data-center/a100/)，所以 `156/312=0.5` 得到 50% MFU。

实践中：
- 对于 NVIDIA GPU，如果你在多节点设置上使用大型模型，MFU 超过 50%，你已经做得非常出色了
- 最近更高效的可伸缩性解决方案的进步不断提高 MFU
- 慢速网络和低效框架或未经优化的配置会降低 MFU

因此，一旦您知道了 MFU，您现在就可以调整上一节中的成本估算。在那个例子中，我们说训练需要 7 天，但如果 MFU 是 50%，这意味着训练需要 14 天。

### 移动比特

为什么无法达到宣传的 TFLOPS？这是因为在加速器内存和计算之间移动数据需要时间，此外，将数据从磁盘和其他 GPU 移动到加速器内存需要更多时间。

- 对于加速器内存，能做的并不多，因为它的带宽就是那样 - 只能编写更高效的软件来使数据更快地传入/传出加速器 - 提示：融合和自定义编写的内核（如 [torch.compile](https://pytorch.org/docs/stable/generated/torch.compile.html) 和 [flash attention](https://github.com/Dao-AILab/flash-attention)）

- 如果你只有一个 GPU 并且模型适合其内存，你就不需要担心网络 - 加速器内存是唯一的瓶颈。但是如果你必须[在多个 GPU 之间分片模型](../training/model-parallelism)，网络就成了瓶颈。

- 节点内网络 - 非常快，但对于大型模型很难利用 - [张量并行](../training/model-parallelism#tensor-parallelism) 和 [序列并行](../training/model-parallelism#sequence-parallelism) 解决了部分问题。（[更多](../network/README.md#intra-node-networking)）。

- 节点间网络 - 在大多数服务器设置上通常太慢 - 因此这是需要研究的关键组件！高效的框架通过重叠计算和通信成功地部分隐藏了通信开销。但是如果通信时间比计算时间长，通信仍然是瓶颈。[更多](#inter-node-network)。

- 存储 IO 主要对为 DataLoader 工作进程提供数据和保存检查点很重要。[更多](#storage)。

  1. 通常有足够的 DL 工作进程，DataLoader 增加的开销很小。
  2. 在保存检查点时，除非使用某种异步保存解决方案，否则加速器会空闲，因此快速 IO 在这里至关重要。

## 关键硬件组件

### 加速器

截至本文撰写时，以下是可用于训练、微调和推理 ML 模型的最常见加速器：

广泛可用：

  * NVIDIA H200s 正在逐渐取代 A100s 和 H100s。H200s 拥有更多且更高效的 HBM，因此比 H100s 更具成本效益。

可用，但会将你锁定：

  * Google TPU - 速度快！但成本是锁定在单一供应商和云中

新兴至普遍可用：

  * NVIDIA H200 - 比 H100 更快的 HBM 和更多内存 - 2024 年第四季度在部分云上提供（并非所有大型云都计划备货这些）。

  * NVIDIA B200 和 GB200 - 正在开始出现。

  * AMD MI355X 正在 Neo 云上出现

  * Intel Gaudi3 > H200 - 在 Intel 的云上可用

  * Amazon 的 Trainium2 < H100 在 AWS 上可用

  * GraphCore IPU - 非常难找到，如果能找到的话，曾在 paperspace 上短暂可用，但现在没有了。

  * Cerebras WaferScale Engine - 在 Cerebras 的云上可用

有关完整列表和最近宣布的加速器，请参阅[加速器](../compute/accelerator)。

#### 加速器互操作性

总的来说，大多数（所有？）加速器都受到 PyTorch 或 TensorFlow 等主要框架的支持，只要不使用任何特定于加速器的功能，相同的代码应该可以在任何地方运行，只需稍作修改。

例如，如果您的 PyTorch 应用程序调用 `torch.mm` - 它应该可以在任何地方工作，但如果它包含自定义 CUDA 内核，它将只在 NVIDIA GPU 上工作，也许在最近的 AMD MI 系列上也可以。

- NVIDIA GPU：全部基于 [CUDA](https://developer.nvidia.com/cuda-toolkit)，大多数训练框架都支持。您可以轻松地在不同的 NVIDIA GPU 之间移动，大多数东西都会同样工作。

- AMD MI250/MI300X：使用 [ROCm](https://pytorch.org/blog/pytorch-for-amd-rocm-platform-now-available-as-python-package/) 的 PyTorch 可以按原样运行大多数基于 CUDA 的软件。这确实是唯一能与 NVIDIA 堆栈互操作的加速器。

- Intel Gaudi2/Gaudi3：如果您使用 HF Transformers/Diffusers，您可以使用 [optimum-habana](https://github.com/huggingface/optimum-habana)。如果您使用 HF Trainer 与 NVIDIA GPU，切换到在 Gaudi2 上进行训练/推理应该相对容易。

- GraphCore IPU：也可以通过 PyTorch 经由 [poptorch](https://github.com/graphcore/poptorch) 运行

- Cerebras：也正在通过 [Cerebras 软件平台 (CSoft) 经由 XLA](https://www.cerebras.net/blog/supporting-pytorch-on-the-cerebras-wafer-scale-engine/) 支持 PyTorch。

此外，一般来说，大多数 ML 代码都可以编译成跨平台格式，如 [Open Neural Network Exchange (ONNX)](https://en.wikipedia.org/wiki/Open_Neural_Network_Exchange)，它可以在各种加速器上运行。这种方法通常更多地用于推理工作负载。

### 网络

- 如果您想训练一个无法容纳在单个加速器内存中的大型模型，您必须依靠节点内和节点间网络来同步多个加速器。

- 目前最大的问题是计算硬件的进步速度快于网络硬件，例如 NVIDIA NVLink 节点内（单向带宽）：

| GPU | 计算<br>fp16<br>TFLOPS | 计算<br>加速比 | 节点内<br>GBps | 节点内<br>加速比 |
| :--- | --: | --: | --: | --: |
| V100 | 125 | 1 | 150 | 1 |
| A100 | 312 | 2.5 | 300 | 2 |
| H100 | 989 | 8 | 450 | 3 |
| B200 | 2250 | 18 | 900 | 6 |

- 你可以看到 A100 比 V100 快 2.5 倍，H100 比 A100 快约 3 倍。但 NVLink 的节点内速度每一代只增加了 150GBps。NVLink 5.0 的速度是 NVLink 4.0 的两倍，所以它在计算速度上有所追赶。但速度提升仍然不足。

- 此外，前 4 代 NVLink 使用相同的 NIC，单向带宽均为 25GBps。他们只是将链路数量加倍和三倍以提高速度。所以那项技术没有取得任何进展。

- 节点间的情况也好不到哪里去，大多数 NIC 的速度为 100 或 200Gbps，一些 400Gbps 的 NIC 开始出现。（相应地以 GBps 为单位：12.5、25 和 50）。这里也是同样的故事，一些解决方案提供数十个 NIC 以获得更高的速度。

- 此外，对于 LLM 来说，有效载荷通常很大，以至于网络延迟对于训练来说通常可以忽略不计。但对于推理来说仍然非常重要。

#### 节点内网络

- 注意字节与比特。1Byte = 8bits。1GBps = 8Gbps。

- 如果您需要在多个节点之间减少比特（例如梯度），那么最慢的链接（节点间）决定了整体吞吐量，因此节点内速度无关紧要

- [张量并行](../training/model-parallelism#tensor-parallelism) 和 [序列并行](../training/model-parallelism#sequence-parallelism) 必须保持在节点内才能高效 - 只有在节点内速度快的情况下才有意义

NVIDIA：

- 基于 NVIDIA 的计算节点配备 50GBps 双工 NVLInk

- 有些有很多 NVLink，其他的较少，但通常足够，H100 至少有 450GBps (3.6Tbps) 的单向带宽，A100 节点有 300GBps

Intel Gaudi2:

- 8 x 21 个 100GbE RoCE v2 ROMA 网卡，总计 2.1TBps

[更多详情](../network/README.md#intra-node-networking)

#### 节点间网络

- 比节点内网络慢一个数量级

- 你会看到从 50Gbps 到 3200 Gbps 的各种速度

- 你需要比计算更快地减少梯度和其他比特，以避免加速器空闲

- 你通常最多只能获得宣传速度的 80%。例如，如果你被告知你得到 800Gbps，预计约为 640Gbps。

- 如果转向 fp8，H100 比 V100 快 18 倍

- 我们尚未看到 H100 的 3200Gbps 是否足以保持高 MFU。


* 实际上不到 3 倍，但这是一个很好的估计

[更多详情](../network/README.md#inter-node-networking)。

### 存储

在 ML 工作负载中，有 3 种不同的存储 IO 需求：

1. 您需要能够快速为 DataLoader 提供数据 - （超快读取，不关心快速写入） - 需要持续数小时和数天的可持续负载
2. 您需要能够快速写入检查点 - （超快写入，快速读取，因为您将恢复几次） - 需要突发写入 - 您希望速度超快，以免长时间阻塞训练（除非您使用某种 cpu 卸载来快速解除训练阻塞）
3. 您需要能够加载和维护您的代码库 - （中速读写） - 这也需要共享，因为您希望所有节点都看到相同的代码库 - 因为它只在开始或恢复时发生，所以会不经常发生

- 大多数时候，你买到的东西只有你付钱买的 80%。如果你想要一个可靠的 100TB，你需要租用 125TB，否则你的应用程序可能会在磁盘满之前很久就写入失败。

- 共享分布式文件系统：
  1. 如果你有大量小文件（=Python！），非并行共享文件系统可能会非常慢
  2. 你想要并行文件系统，如 GPFS (IBM Spectrum Scale) 或 Lustre (开源)

[更多详情](../storage/README.md)。

### CPU 内存

您需要足够的内存用于：

- 每个加速器 2-3 个可能的 DL 工作进程（因此每个节点 8 个加速器，就有 16-24 个进程）

- 如果您从云端拉取数据，DL 工作进程需要更多内存

- 如果您不能直接加载到加速器，需要足够的内存来加载模型

- 通常用于加速器内存卸载 - 通过换出当前未使用的层来扩展加速器的内存 - 如果这是目标用途，那么可用的 cpu 内存越多越好！

### CPU

这可能是最不令人担忧的组件。

- 大多数云提供商都提供强大的 CPU 和充足的 cpu 内核

- 你需要有足够的内核来运行每个 gpu 2-3 个 DL 工作进程 +1 - 所以至少需要 30 个内核

- 如果你有复杂和/或缓慢的 DL 转换（CV），则需要更多内核用于 DL 工作进程

- 大部分计算都在 GPU 上进行

## 用你的 ML 即时数学给别人留下深刻印象

### 在 5 秒内说出你需要多少个 GPU

- 半混合精度训练：`模型大小（B）* 18 * 1.25 / GPU 内存大小（GB）`

- 半精度推理：`模型大小（B）* 2 * 1.25 / GPU 内存大小（GB）`

这是最低要求，更多是为了有更大的批量大小和更长的序列长度。

以下是细分：

- 训练：8 字节用于 AdamW 状态，4 字节用于梯度，4+2 字节用于权重

- 推理：2 字节用于权重（如果使用量化，则为 1 字节）

- 1.25 是 25% 用于激活（非常非常近似）

例如：我们以一个 80B 参数的模型和 80GB 的 GPU 为例，计算我们需要多少个 GPU 用于：

- 训练：至少 23 个 GPU `80*18*1.25/80`
- 推理：至少 3 个 GPU `80*2*1.25/80`

[更多详情](../training/performance/README.md#anatomy-of-models-memory-usage)。

## 需要注意的陷阱

在您驾驭这个非常复杂的 AI 行业时，需要注意以下几点：

### 对"将尽合理努力……"的合同说不

- 如果你的合同没有明确的交付成果（时间和性能），如果你为得不到的东西付费，或者没有按时收到，或者根本收不到，不要感到惊讶

- 在签署包含"我们将尽合理努力……"等条款的合同之前要非常小心。

   你上一次去超市面包区发现一块半生不熟的面团，上面写着"我们尽了合理的努力来烤这个面包，但可惜，你看到的就是你得到的"是什么时候？

   但无论出于何种原因，创建一个法律合同是可以接受的，其中提供商既不提供交货日期也不提供性能指标，并且不规定当这些承诺未兑现时他们将如何赔偿。

### 警惕硬件和软件锁定场景

- 一些云提供商会让你使用非常专有的工具或硬件，这会让你以后很难离开，因为如果你离开，你将不得不重新装备一切
- 考虑一下如果该提供商被证明不令人满意，或者他们没有能力满足您日益增长的需求，那么迁移到另一个提供商的成本会是多少。
- 如果您租用一个带有通用 Linux 系统和通用开源工具的集群，那么从一个提供商迁移到另一个提供商应该很简单，因为几乎所有东西都可以开箱即用

- 显然，如果您选择需要特定硬件才能工作的定制软件，并且您无法在其他任何地方租用此硬件，那么您就是在为自己设置锁定

### 不要买你真正不需要的东西

- 云提供商大多拥有相同的通用硬件，这导致利润率非常微薄，因此为了赚大钱，他们发明产品，然后试图说服您需要购买它们。有时您确实需要这些产品，但通常情况下并非如此。另请参阅上一节关于锁定的内容，因为专有产品通常意味着部分锁定。

- 通常很容易观察到寻求问题解决方案的解决方案的三步营销技巧：

  1. 通过给予巨额折扣甚至付费使用，说服几位备受尊敬的客户使用提供商的专有产品
  2. 利用步骤 1 中的那些作为社会认可的杠杆，吸引更多的皈依者
  3. 然后通过告诉他们 80% 的客户（1+2）都在使用这些神奇的产品，来网罗其余的挣扎者

在营销这些产品时，重要的是：

- 提及它们与其他十几种产品的配合程度，因为现在你不仅仅是购买一个产品，而是购买一个完整的专有产品领域。
- 使用看起来非常漂亮的复杂图表，说明事物如何相互插入，并在有人提出难题之前迅速转到下一张幻灯片。

HPC 可能是值得学习的一组计算提供商 - 他们没有资金来创建新产品，因此他们创造性地使用主要是通用的开源工具来满足所有需求，并在绝对需要时添加一些自定义编写的软件。

## 不请自来的建议

最后，我想分享一些关于如何稍微改善日常 AI 战场体验的见解。

### FOMO 与避免抑郁

如果你阅读 Twitter 和其他类似的 ML 相关信息流，你肯定会感到错失恐惧症（FOMO），因为每周可能至少有一个伟大的新模型发布，每天都有多篇论文发表，你的同行每隔几分钟就会发布他们很酷的成就。

我们正在处理**非常复杂**的技术，只有少数人能够吸收如此多的新材料并理解/整合它。

这可能会非常令人沮丧和泄气。

我每周大约看一两次推特来应对这种情况。我主要以广播模式使用推特 - 也就是说，如果我有什么要分享的，我就会发布它，只关注可能出现的后续问题。

通常所有重要的新闻都是通过其他人传到我这里的。

### 不要试图知道一切

AI 领域的创新速度是惊人的。不可能知道所有关于 AI 的事情。我敢说，对我们大多数人来说，甚至不可能知道其中的 10%。

我很早就意识到了这一点，我不再关注大多数公告、教程、主题演讲等。每当我有一个新的需求时，我就会研究它，我发现我需要什么，我必须小心不要试图学习与手头目标无关的其他事情。

所以我实际上知道的很少，但我深入研究过的东西，我在一段时间内知道得很好，后来我甚至忘记了（这就是为什么我写这些笔记 - 这样我就可以轻松找到我已经研究过的东西）。

所以如果你问我什么，我很有可能不知道，但我的优点是，如果你给我时间，我可以弄清楚并给出答案或开发一个解决方案。

### 使用半成品软件时不要自责

由于 ML 领域正处于一场巨大的竞赛中，许多开源软件都是半成品、文档不佳、测试不佳，有时支持也很差。因此，如果你认为通过重用他人编写的软件可以节省时间，那么预计要花费数小时到数周的时间来弄清楚如何让它工作。然后在更新破坏它时保持它的工作。

下一个问题是，这些软件中的大多数都依赖于其他软件，而这些软件通常也同样糟糕。我开始修复一些集成问题，结果发现一个依赖包有问题，而这个依赖包又有另一个来自另一个包的问题，这种情况并不少见。这可能会非常令人沮丧和泄气。人们试图通过代码重用来节省时间，但最终却花费很长时间来弄清楚如何让它工作。至少如果我编写自己的软件，我会感到有趣，这是一个创造性的过程，而试图让别人的软件工作则不然。

所以归根结底，我们仍然最好重用别人的软件，只是它会带来情感上的代价和疲惫。

所以首先，试着找到一种方法，如果不是你写的软件不工作，不要自责。如果你想一想，那些问题不是你造成的。

学习如何[高效调试](https://github.com/stas00/the-art-of-debugging/tree/master/methodology)也应该使这个过程不那么痛苦。
