---
title: 自述文件
createTime: 2025/07/03 00:05:24
permalink: /notes/notes/0cr0lrdz/
---
# CPU 内存

这是一个很小的章节，因为通常关于 CPU 内存需要知道的细微差别很少——这是件好事！

大部分 ML 工作负载的计算都在 GPU 上进行，但通常每个节点上的 CPU 内存至少应该与 GPU 上的内存一样多。因此，例如，如果您在一个拥有 8 个 80GB GPU 的 H100 节点上，您就有 640GB 的 GPU 内存。因此，您至少需要同样多的 CPU 内存。但最近的高端云套餐通常都配备 1-2TB 的 CPU 内存。

## ML 工作负载中需要 CPU 内存做什么

- 加载模型权重，除非它们直接加载到 GPU 上——这通常是临时内存使用，一旦模型被移动到 GPU，就会恢复为零。
- 保存模型权重。在某些情况下，每个 GPU 将自己的检查点直接写入磁盘，在其他情况下，模型在写入磁盘之前在 CPU 上重新组合——这也是临时的内存使用。
- 当使用像 [Deepspeed](https://www.deepspeed.ai/tutorials/zero-offload/) 这样的框架时，可能会进行参数和优化器状态的卸载。在这种情况下，可能需要相当多的 CPU 内存。
- 在 `forward` 传递中计算的、并且需要为 `backward` 路径可用的激活也可以卸载到 CPU，而不是丢弃然后在后向传递期间重新计算以节省不必要的开销。
- `DataLoader` 通常是 CPU 内存的主要用户之一，有时它可能会消耗非常大量的内存。通常每个节点上至少运行 2 个 8 DL 工作进程，因此您需要足够的内存来支持至少 16 个进程，每个进程都持有某些数据。例如，在从云端流式传输数据的情况下，如果数据分片很大，这些进程很容易占用数百 GB 的 CPU 内存。
- 软件本身及其依赖库会使用少量 CPU 内存，但这通常可以忽略不计。

## 需要知道的事情

- 如果 `DataLoader` 以 `mmap` 模式使用 HF `datasets`，驻留内存使用量可能会显得非常大，因为它会尝试将整个数据集映射到内存中。但这具有误导性，因为如果其他地方需要内存，操作系统会将任何不需要的 mmap 页面换回系统。您可以在[此处](https://stasosphere.com/entrepreneur-being/301-mmap-memory-leak-investigation/)阅读更多相关信息。当然，这种意识适用于任何使用 `mmap` 的数据集，我使用 HF `datasets` 作为一个例子，因为它被广泛使用。
