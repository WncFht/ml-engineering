---
title: 自述文件
createTime: 2025/07/03 00:05:24
permalink: /notes/notes/64lkx5bq/
---
# CPU

截至本文撰写之时，机器学习工作负载不使用太多 CPU，因此本章没有太多内容可讲。随着 CPU 发展得越来越像 GPU，这种情况可能会改变，所以我预计本章会随着 CPU 的发展而发展。

## 你需要多少个 CPU 核心

每个加速器您需要：

1. 每个与加速器绑定的进程需要 1 个 cpu 核心
2. 每个 `DataLoader` 工作进程需要 1 个 cpu 核心 - 通常您需要 2-4 个工作进程。

对于语言模型来说，2 个工作进程通常就足够了，特别是如果数据已经预处理过。

如果您需要进行动态转换，这在计算机视觉模型或 VLM 中通常是这种情况，您可能需要 3-4 个甚至更多的工作进程。

目标是能够立即从 `DataLoader` 中拉取数据，而不是阻塞加速器的计算，这意味着您需要在当前迭代运行时为下一次迭代预处理一批样本。换句话说，您的下一批处理时间不应超过相同大小批次的单次迭代加速器计算时间。

除了预处理，如果您从云端动态拉取数据而不是本地存储，您还需要确保数据预取足够快，以喂饱那些为加速器熔炉提供数据的工作进程。

将其乘以加速器的数量，再加上几个用于操作系统的核心（比如说 4 个）。

如果节点有 8 个加速器，并且您有 n_workers，那么您需要 `8*(num_workers+1)+4`。如果您正在做 NLP，通常每个加速器大约需要 2 个工作进程，所以 `8*(2+1)+4` => 28 个 cpu 核心。如果您正在做 CV 训练，并且，比如说，每个加速器需要 4 个工作进程，那么就是 `8(4+1)+4` => 44 个 cpu 核心。

如果您有比 CPU 核心总数还多的非常活跃的进程会发生什么？一些进程会被抢占（放入队列中，等待 CPU 核心可用），您绝对希望避免任何上下文切换。

但现代云产品通常有 50-100+ 个 cpu 核心，所以通常不愁没有足够的核可用。

另请参阅[异步 DataLoader](../../training/performance#asynchronous-dataloader)。

### CPU 卸载

一些框架，比如 [Deepspeed](https://www.deepspeed.ai/tutorials/zero-offload/)，可以将一些计算工作卸载到 CPU 而不产生瓶颈。在这种情况下，您会需要额外的 cpu 核心。

## NUMA 亲和性

请参阅[NUMA 亲和性](../../training/performance#numa-affinity)。

## 超线程

[超线程](https://en.wikipedia.org/wiki/Hyper-threading)通过将每个物理核心虚拟化为 2 个虚拟核心，使 cpu 核心数量加倍，允许 2 个线程同时使用同一个 cpu 核心。根据工作负载的类型，此功能可能会也可能不会提高整体性能。该技术的发明者英特尔表示，在某些情况下可能会有 30% 的性能提升。

另请参阅[是否启用超线程](../../orchestration/slurm/performance.md#to-enable-hyper-threads-or-not)。
