---
title: 超参数
createTime: 2025/07/03 00:05:24
permalink: /notes/notes/z5fo289c/
---
# 选择训练超参数和模型初始化

找到一个好的超参数和模型初始化入门集的最简单方法是从一个你知道已经成功的类似训练中"窃取"它。这里有一个[公开可用的训练 LLM/VLM 日志集合](../resources/README.md#publicly-available-training-llmvlm-logbooks)来帮助你入门。另一个常见的来源是论文，如果它们披露了这些信息。如果作者没有公布这些细节，你也可以尝试联系他们索取。

## 术语表

训练行话使用了大量的缩写和术语，所以这里有一些对本章很重要的术语。

- BS: 批量大小 - 这里我们指的是每个 gpu 的批量大小，通常也称为 MBS（微批量大小）
- GBS: 全局批量大小 - 每次迭代的总批量大小 - 可能包括梯度累积
- GAS: 梯度累积步数 - 在完成一次完整迭代之前执行多少次前向/后向循环
- TFLOPs: 每秒万亿次浮点运算 - [FLOPS](https://en.wikipedia.org/wiki/FLOPS)
- PP: 流水线并行

## 全局批量大小提升

如果你打算用一个非常大的 GBS 进行训练，比如 1024、2048 个样本甚至更高，当你刚开始训练时，向模型提供如此大的批量大小是非常浪费的。在这一点上，模型完全是随机的，无法从过于精细的数据中受益。因此，为了节省数据和资源，人们通常会在一段时间内逐步增加全局批量大小。

同样重要的是，不要从太小的 GBS 开始，否则进度会不高效。当数据太少时，计算（TFLOPS）效率低下，会减慢一切。当使用流水线并行（PP）时尤其如此，因为 PP 调优最重要的事情是一个小的 GPU 空闲气泡，GBS 越小，气泡就越大。

例如，对于 BLOOM-176B，我们确实使用了 PP，在进行吞吐量基准测试后，我们发现从 GBS=16 开始非常慢（8 TFLOPs），所以我们最终从 GBS=192 开始（73 TFLOPS），然后我们提升到 GBS=2048（150 TFLOPS）- 我们每 9,765,625 个样本将 GBS 增加 16。



### STD 初始化

这个超参数非常重要，需要通过数学计算才能正确设置。有关详细信息，请参阅 [STD 初始化](instabilities#std-init)。
